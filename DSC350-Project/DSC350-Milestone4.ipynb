{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row 664: Expected 13 columns, found 1\n",
      "Extracted 663 rows of data.\n",
      "Combine data retrieval complete.\n",
      "   Year                 Name         College Position  Height  Weight  \\\n",
      "0  2019       Britton Abbott  Oklahoma State       FB   74.25     246   \n",
      "1  2019      Micah Abernathy       Tennessee       FS   71.63     195   \n",
      "3  2019           Paul Adams        Missouri       OT   77.88     317   \n",
      "4  2019       Nasir Adderley        Delaware        S   71.75     206   \n",
      "5  2019  Freedom Akinmoladun        Nebraska       DT   75.25     284   \n",
      "\n",
      "   40_Yard  Bench_Press  Vertical_Leap  Broad_Jump  Shuttle  3_Cone  \n",
      "0     4.75         19.0           36.0       111.0     4.45    7.45  \n",
      "1     4.52         15.0           38.5       130.0     4.09    6.69  \n",
      "3     5.18         16.0           27.0       103.0     4.74     NaN  \n",
      "4     4.62         19.0           38.0       129.0      NaN     NaN  \n",
      "5     4.96         19.0           33.0       118.0     4.62    7.35  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Andres Melendez\n",
    "Description: This script scrapes NFL Combine data for 2019 from a specified website, performs data extraction using Selenium, \n",
    "and includes data transformation and cleansing steps to ensure consistency and readability.\n",
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_combine_data_selenium(url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Opens the specified URL using Selenium, extracts NFL Combine data, and parses it into a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL containing the NFL Combine data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the raw, extracted data.\n",
    "    \"\"\"\n",
    "    service = Service(r'C:\\Users\\2dre3\\OneDrive\\Documents\\chromedriver-win64\\chromedriver.exe')\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    \n",
    "    try:\n",
    "        # Load the target webpage\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Parse the page's HTML\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        \n",
    "        if not table:\n",
    "            print(\"No table found on the page.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Define headers based on known column structure\n",
    "        headers = ['Year', 'Name', 'College', 'Position', 'Height', 'Weight', 'Wonderlic',\n",
    "                   '40_Yard', 'Bench_Press', 'Vertical_Leap', 'Broad_Jump', 'Shuttle', '3_Cone']\n",
    "\n",
    "        rows = []\n",
    "        for i, row in enumerate(table.find_all('tr')[1:], start=1):\n",
    "            # Extract each cell's text content\n",
    "            cols = [td.text.strip() for td in row.find_all('td')]\n",
    "            \n",
    "            # Verify that the row matches the expected column count\n",
    "            if len(cols) == len(headers):\n",
    "                rows.append(cols)\n",
    "            else:\n",
    "                print(f\"Skipping row {i}: Expected {len(headers)} columns, found {len(cols)}\")\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"Data extraction completed, but no rows were found.\")\n",
    "        else:\n",
    "            print(f\"Extracted {len(df)} rows of data.\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "        print(\"Combine data retrieval complete.\")\n",
    "\n",
    "def clean_and_transform_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and transforms the extracted NFL Combine data by converting columns, handling missing values, \n",
    "    and standardizing text formats.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The raw DataFrame containing extracted data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the cleaned and transformed data.\n",
    "    \"\"\"\n",
    "    df.columns = ['Year', 'Name', 'College', 'Position', 'Height', 'Weight', 'Wonderlic',\n",
    "                  '40_Yard', 'Bench_Press', 'Vertical_Leap', 'Broad_Jump', 'Shuttle', '3_Cone']\n",
    "    \n",
    "    # Drop the Wonderlic column\n",
    "    df = df.drop(columns=['Wonderlic'])\n",
    "\n",
    "    # Convert 'Weight' to numeric\n",
    "    df['Weight'] = pd.to_numeric(df['Weight'], errors='coerce')\n",
    "    \n",
    "    # Convert 'Height' to inches, handling both string and numeric formats\n",
    "    def height_to_inches(height):\n",
    "        if isinstance(height, str) and '-' in height:\n",
    "            feet, inches = height.split('-')\n",
    "            return int(feet) * 12 + int(inches)\n",
    "        return pd.to_numeric(height, errors='coerce')\n",
    "    \n",
    "    df['Height'] = df['Height'].apply(height_to_inches)\n",
    "\n",
    "    # Convert numeric performance columns to proper data types\n",
    "    numeric_cols = ['40_Yard', 'Bench_Press', 'Vertical_Leap', 'Broad_Jump', 'Shuttle', '3_Cone']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Standardize 'Position' and 'College' formats for consistency\n",
    "    df['Position'] = df['Position'].str.upper()\n",
    "    df['College'] = df['College'].str.title()\n",
    "    \n",
    "    # Remove duplicate rows to ensure unique entries\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Drop rows with missing values in essential performance columns\n",
    "    df = df.dropna(subset=['40_Yard', 'Bench_Press', 'Height', 'Weight'])\n",
    "    \n",
    "    # If your notebook contains a DataFrame named `df`, export it:\n",
    "    df.to_csv('player_combine.csv', index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the data extraction and transformation process.\n",
    "    \"\"\"\n",
    "    url = 'https://nflcombineresults.com/nflcombinedata.php?year=2019&pos=&college='\n",
    "    combine_data = fetch_combine_data_selenium(url)\n",
    "    \n",
    "    if not combine_data.empty:\n",
    "        transformed_data = clean_and_transform_data(combine_data)\n",
    "        print(transformed_data.head())\n",
    "    else:\n",
    "        print(\"No data available for transformation.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
